\documentclass{scarv-report}

\title{{\tt lab.scarv.org}}
\date{Version $0.1.0$ (\today)}
\author{Daniel Page}
\author{James Webb}
\affil{
Department of Computer Science, University of Bristol,\\
Merchant Venturers Building, Woodland Road,\\
Bristol, BS8 1UB, United Kingdom.\\
\url{daniel.page@bristol.ac.uk}
}

\begin{document}

% =============================================================================

\MKPROLOGUE

% =============================================================================

\section{Introduction}
\label{sec:intro}

\import{./tex/}{intro.tex}

% =============================================================================

%<!-- ====================================================================== -->
%
%# Background
%
%- Focusing on power- and EM-based side-channel attacks, the process of
%  acquiring a trace of execution behaviour will typically involve the
%  following components:
%
%  1. *A  target      device*.
%     This is the subject of the attack, so the device from which traces
%     of execution behaviour stemming from a *target implementation* are 
%     acquired.
%     Example: a micro-controller or FPGA.
%
%  2. *An acquisition device*.
%     This produces time series data, i.e., a trace, reflecting samples 
%     of the behaviour exhibited by the target device (wrt. a relevant 
%     form of side-channel).
%     Example: an oscilloscope, which samples voltage levels associated
%     with (and so fluctuating as a result of) the target device power
%     supply, plus associated equipment (e.g., an amplifier).
%
%  3. *A  control     device*.
%     This is (physically) connected to both the target and acquisition 
%     device, and is tasked with orchestrating the *acquisition process*.
%     Example: a standard workstation.
%
%  We collectively term these components the *acquisition appliance*.
%
%- The acquisition process could be summarised as follows:
%
%  1. the 
%     control     device 
%     programs the
%     target      device
%     with the target implementation.
%  2. the 
%     control     device
%     configures the 
%     acquisition device
%     st. a positive edge on the trigger signal starts acquisition of a
%     trace.
%  3. the 
%     control     device 
%     sends a request (or command) to the 
%     target      device,
%     including any  input data `x`,
%
%  4. the target  device 
%
%     - sets the trigger signal to `1` (i.e., produces a positive edge),
%     - executes the target implementation to compute `r = f_i( x )`,
%     - sets the trigger signal to `0` (i.e., produces a negative edge),
%
%  5. the 
%     target      device 
%     sends a response             to the 
%     control     device,
%     including any output data `r`,
%  6. the
%     control     device
%     retrieves the acquired trace from the
%     acquisition device.
%
%  Acquisition of more than one trace, which is typical, means iterating
%  over steps 2. to 6. inclusive.
%
%- Various challenges are abstracted in the above, not least the cost of
%  owning and operating the acquisition appliance; at a high-level then,
%  the goal is to offer access to an acquisition appliance as a (remote) 
%  service.
%
%- Once a set of some number of traces (a trace set) has been acquired, 
%  the next step is to apply one or more *attack implementations* so as
%  to recover a security-critical target value(s).
%
%<!-- ====================================================================== -->
%
%# Step #1: stand-alone acquisition infrastructure
%
%- At this stage the idea is to support a use-case focused on acquisition
%  and storage of traces.  
%  The user in this use-case would interact with a EC2 *front-end server* 
%  via either
%
%  - a web-based interface, 
%    or
%  - a command-line interface (likely an AWS-like wrapper around the
%    web-based interface)
%
%  to submit an 
%  *acquisition job manifest* 
%  serviced by an
%  acquisition appliance; 
%  the 
%  *acquisition data set*, 
%  i.e., output from the 
%  acquisition process,
%  is transferred to an S3 bucket.
%
%- An acquisition appliance will pull an acquisition job manifest from
%  an *acquisition job queue* (or an intermediary) to decouple workload
%  produced by users from the acquisition appliance.
%
%  Note that:
%
%  - Use of "an" vs. "the" acquisition appliance is intentional, since
%    use of multiple instances could make sense (e.g., to load balance, 
%    or cater for special-case target devices).
%  - Use of a pull-based approach is intended to reduce exposure of the 
%    acquisition appliance.  If the acquisition job queue were to push 
%    acquisition job manifests, the acquisition appliance would need to
%    expose an associated API (i.e., a server); this would need to be
%    hardened against misuse (e.g., DoS-based attack ).
%
%- A given acquisition job manifest is represented as a JSON object; the
%  syntax of such objects is outlined by the schema 
%  `SCHEMA_JOB`
%  in
%  `src/acquire/share/schema.py';
%  there is an example in
%  `example/example.job`.
%
%  | Key                     | Purpose                                                                                                                                                                                    |
%  |-------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
%  | `version`               | a  version number      for the acquisition job (e.g., to allow evolution of the acquisition job manifest syntax)                                                                           |
%  | `id`                    | a  (unique) identifier for the acquisition job                                                                                                                                             |
%  | `driver-id`             | an identifier    for or type of the driver with which to interact with the target implementation  (e.g., `block` for a block cipher)                                                       |
%  | `driver-spec`           | a  specification object for the driver identified by `driver-id`                                  (e.g., including information about how to generate inputs for the target implementation) |
%  | `device-id`             | an identifier    for or type of the (combination of) target and acquisition device from which to acquire traces of execution behaviour                                                     |
%  | `repo-id`               | an identifier    for or type of the repository from which the target implementation is downloaded (e.g., `git` for a git repository)                                                       |
%  | `repo-spec`             | a  specification object for the repository identified by `repo-id`                                (e.g., including a git URL)                                                              |
%  | `depo-id`               | an identifier    for or type of the depository into which the acquisition data set  is   uploaded (e.g., `s3` for an S3 bucket)                                                            |
%  | `depo-spec`             | a  specification object for the depository identified by `depo-id`                                (e.g., including an S3 bucket identifier)                                                |
%  | `trace-spec`            | a  specification object for the traces acquired                                                   (e.g., number, format)                                                                   |
%
%- The 
%  target implementation 
%  must conform to an API associated with the stated type; 
%  for example, stating the target implementation is of some block cipher 
%  might demand there is an entry point
%
%  ```
%  void enc( uint8_t* c, uint8_t* m, uint8_t* k );
%  ```
%
%  When built by the 
%  acquisition appliance, 
%  it will be linked against a
%  (public) 
%  *acquisition library*: 
%  this wraps the 
%  target implementation 
%  in a harness to make it suitable for use
%  (e.g., by manipulating the trigger signal correctly).
%
%- The 
%  acquisition appliance 
%  follows roughly these steps:
%
%  1. check whether the 
%     acquisition data set 
%     already exists, and act appropriately,
%  2. clone the 
%     target implementation 
%     repository into local storage,
%  3. build the 
%     target implementation 
%     against the 
%     acquisition library,
%  4. program the target device with the target implementation,
%  5. test the target implementation, e.g.,
%
%     - how long does it take to execute,
%     - does it function as a block cipher.
%
%  6. execute the acquisition process for however many traces are required,
%     using local storage for the temporary output,
%  7. transfer said output, namely the
%
%     - acquisition job manifest,
%     - (archived) target implementation repository,
%     - acquired traces,
%     - log of the whole process,
%
%     which constitutes an
%     acquisition data set,
%     to the 
%     acquisition job URL.
%
%<!-- ====================================================================== -->
%
%# Step #2: stand-alone attack      infrastructure
%
%- At this stage the idea is to support a use-case focused on use of the
%  results from a previous acquisition, i.e., a stored acquisition data
%  set, through execution of an *attack implementation*.
%  The user in this use-case would interact with a EC2 *front-end server* 
%  via either
%
%  - a web-based interface,
%  - a command-line interface (likely an AWS-like wrapper around the
%    web-based interface)
%
%  to submit an 
%  *attack job manifest* 
%  serviced by an
%  EC2-instance, which we term the *attack appliance*, using
%  an acquisition data set (stored in an S3 bucket) as input;
%  the 
%  *attack data set*, 
%  i.e., output from the 
%  attack process,
%  is transferred to an S3 bucket.
%
%- One could imagine either
%
%  - creating attack appliance instances on demand (suggesting use of AWS 
%    Lambda),
%    or
%  - maintaining a pool of such instances, each of which pulls attack job
%    manifests from a single queue.
%
%- An
%  attack job manifest
%  must include fields that capture:
%
%  - an attack implementation ID (or type), 
%    e.g., block cipher,
%  - an attack implementation URL, 
%    namely a git URL of a repository that contains it,
%  - an acquisition job URL,
%    i.e., the acquisition data set against which to execute the attack.
%
%- Most of the notes about acquisition job manifests also apply to attack
%  job manifests, e.g., wrt. *attack job IDs* and *attack job URLs*. 
%
%- The 
%  attack implementation 
%  must conform to an API associated with the stated type.
%  When built by the 
%  attack appliance, 
%  it will be linked against a
%  (public) 
%  *attack library*: 
%  this wraps the 
%  attack implementation 
%  in a harness to make it suitable for use.
%
%- The 
%  acquisition appliance 
%  follows roughly these steps:
%
%  1. check whether the 
%     attack data set 
%     already exists, and act appropriately,
%  2. clone the 
%     attack implementation 
%     repository into local storage,
%  3. build the 
%     attack implementation 
%     against the 
%     attack library,
%  4. execute the 
%     attack implementation,
%     using local storage for the temporary output and streaming the input
%     from stated acquisition job URL (i.e., from the S3 bucket),
%  5. transfer said output, namely the
%
%     - attack job manifest,
%     - (archived) attack implementation repository,
%     - attack results,
%     - log of the whole process,
%
%     which constitutes an
%     attack data set,
%     to the 
%     attack job URL.
%
%<!-- ====================================================================== -->
%
%# Step #3: use-cases and embellishments
%
%## Full-on integration: in-cloud development, acquisition, and attack
%
%The idea here would essentially be to bring the development of target and
%attack implementations into the infrastructure, by using an in-cloud IDE.
%To make direct use of the existing acquisition and attack infrastructure,
%the idea would likely be to interface said IDE with git repositories that
%are backed by S3-based storage: as such, the same infrastructure simply
%uses an internal vs. external target or attack implementation URL.
%
%## Applications layered on top of infrastructure
%
%Once developed, the infrastructure can be used as a stand-alone resource
%or support more specific, tailored use-cases: examples include
%
%- (controlled) exposure of the S3 bucket to support a database of trace
%  sets as open access resources,
%- hosting of CTF-like or "build-it, break-it, fix-it" competitions.
%
%In a sense, both could be viewed as web-applications that are layered on
%top of the infrastructure; they essentially just manage or present data 
%that is already available in specific ways.
%
%<!-- ====================================================================== -->
%
%# General notes
%
%- There clearly needs to be some element of user account management, but 
%  this can initially be very lightweight.
%
%- There is a clear danger in that a user can execute somewhat arbitrary,
%  albeit API conformant programs on a target device or attack appliance.
%  One could imagine several approaches to this problem:
%
%  - Ignore it: if users are vetted somehow (or even paying for service),
%    then, provided some effort wrt. sandboxing etc. is in place, there
%    is no real issue.
%  - Put a human in the loop: introduce a second layer of queue to allow
%    some form of manual vetting of acquisition or attack job manifests.
%    Even if this is viable, it is not clear how effective it would be
%    vs. determined malicious use.
%
%- As a starting point, conservative defaults seem sensible; for example,
%  putting an small(ish) upper bound on the number of traces acquires is
%  reasonable to conserve storage space and thus reduce cost.  For a paid
%  served, such defaults can be removed and absorbed into the cost model.
%
%<!-- ====================================================================== -->

% =============================================================================

\MKEPILOGUE

% =============================================================================

\end{document}
